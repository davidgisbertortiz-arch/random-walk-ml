# üìö Gu√≠a de Aprendizaje: Machine Learning en Random Walks

> **Una gu√≠a did√°ctica completa para entender cada concepto, modelo y t√©cnica utilizada en este proyecto**

---

## üéØ √çndice

1. [Conceptos Fundamentales](#-conceptos-fundamentales)
2. [Random Walks Explicados](#-random-walks-explicados)
3. [Feature Engineering](#-feature-engineering)
4. [Modelos de Machine Learning](#-modelos-de-machine-learning)
5. [Validaci√≥n y M√©tricas](#-validaci√≥n-y-m√©tricas)
6. [Group-Aware Validation](#-group-aware-validation-el-concepto-cr√≠tico)
7. [Ejercicios Pr√°cticos](#-ejercicios-pr√°cticos)
8. [Recursos Adicionales](#-recursos-adicionales)

---

## üß† Conceptos Fundamentales

### ¬øQu√© es un Random Walk?

Un **random walk** (caminata aleatoria) es un proceso estoc√°stico donde cada paso es aleatorio e independiente de los anteriores.

**Analog√≠a:** Imagina lanzar una moneda:
- ‚úÖ Cara ‚Üí Das un paso hacia adelante (+1)
- ‚ùå Cruz ‚Üí Das un paso hacia atr√°s (-1)

```python
import numpy as np

# Random walk justo (p=0.5)
steps = np.random.choice([-1, 1], size=100)
position = np.cumsum(steps)  # Posici√≥n acumulada

# Tu trayectoria: [0, -1, 0, 1, 0, -1, -2, -1, ...]
```

**Visualizaci√≥n:**

```
Posici√≥n
   |
 5 |           *
   |        *     *
 0 |  *  *           *
   | *                  *
-5 |________________________
     0  10  20  30  40  50
              Tiempo
```

### Random Walk "Justo" vs "Sesgado"

| Tipo | Probabilidad | Comportamiento | Ejemplo Real |
|------|--------------|----------------|--------------|
| **Justo** | p(+1) = 0.5 | Sin tendencia, totalmente aleatorio | Mercado eficiente |
| **Sesgado positivo** | p(+1) = 0.7 | Tendencia alcista | Mercado alcista |
| **Sesgado negativo** | p(+1) = 0.3 | Tendencia bajista | Mercado bajista |

**Pregunta clave del proyecto:** ¬øPuede ML detectar si un walk es justo o sesgado observando solo una ventana corta de pasos?

---

## üé≤ Random Walks Explicados

### 1. Random Walk 1D (Una Dimensi√≥n)

El m√°s simple: movimiento en una l√≠nea.

```python
from enhanced_model import WalkConfig, generate_random_walks_1d

# Configuraci√≥n
config = WalkConfig(
    n_walks=10,        # Generar 10 caminatas
    n_steps=200,       # Cada una con 200 pasos
    bias_mode="mixed"  # Mezcla de justos y sesgados
)

positions, p_ups = generate_random_walks_1d(config)

print(f"Forma de positions: {positions.shape}")  # (10, 200)
print(f"Probabilidades: {p_ups}")  # [0.5, 0.7, 0.3, ...]
```

**¬øQu√© obtenemos?**
- `positions[i, t]`: Posici√≥n del walk `i` en el tiempo `t`
- `p_ups[i]`: Probabilidad de paso +1 para el walk `i`

**Visualizaci√≥n de un walk sesgado:**

```python
import matplotlib.pyplot as plt

# Walk con sesgo positivo (p=0.7)
steps = np.random.choice([-1, 1], size=500, p=[0.3, 0.7])
position = np.cumsum(steps)

plt.plot(position)
plt.axhline(0, color='red', linestyle='--', label='Inicio')
plt.title('Random Walk Sesgado (p=0.7)')
plt.xlabel('Pasos')
plt.ylabel('Posici√≥n')
plt.legend()
plt.grid(True, alpha=0.3)
```

**Observa:** El walk tiende a subir (m√°s +1 que -1).

### 2. Random Walk 2D (Dos Dimensiones)

Movimiento en un plano (X, Y).

```python
from enhanced_model import generate_random_walks_nd

# Configuraci√≥n 2D
config_2d = WalkConfig(
    n_walks=5,
    n_steps=300,
    dimensions=2,  # ¬°2D!
    bias_mode="mixed"
)

positions_2d, p_ups_2d = generate_random_walks_nd(config_2d)

print(f"Forma: {positions_2d.shape}")  # (5, 300, 2)
#                                         ‚Üë   ‚Üë    ‚Üë
#                                      walks pasos dims

# Cada walk tiene:
# - positions_2d[i, :, 0] ‚Üí trayectoria en X
# - positions_2d[i, :, 1] ‚Üí trayectoria en Y
# - p_ups_2d[i, 0] ‚Üí sesgo en X
# - p_ups_2d[i, 1] ‚Üí sesgo en Y
```

**Aplicaci√≥n pr√°ctica:** Robots, drones, part√≠culas en f√≠sica.

### 3. Mezcla de Walks (Clave del Proyecto)

```python
from enhanced_model import BiasDistribution

# Configurar mezcla
bias_dist = BiasDistribution(
    fair_prob=0.2,              # 20% ser√°n justos (p=0.5)
    positive_bias_prob=0.4,     # 40% sesgo positivo
    negative_bias_prob=0.4,     # 40% sesgo negativo
    positive_bias_range=(0.6, 0.75),  # p entre 0.6 y 0.75
    negative_bias_range=(0.25, 0.4)   # p entre 0.25 y 0.4
)

config = WalkConfig(
    n_walks=100,
    n_steps=500,
    bias_mode="mixed",
    bias_distribution=bias_dist
)
```

**¬øPor qu√© mezclar?**

Si todos fueran justos ‚Üí ML no aprende nada (no hay se√±al)  
Si todos fueran iguales ‚Üí ML aprende pero no generaliza  
**Mezcla realista** ‚Üí ML aprende patrones √∫tiles que funcionan en el mundo real

---

## üîß Feature Engineering

### ¬øQu√© son Features (Caracter√≠sticas)?

Features son las **variables de entrada** que el modelo ML usa para hacer predicciones.

**Problema:** Tenemos una secuencia de posiciones `[10, 11, 9, 10, 12, ...]`  
**Objetivo:** Extraer informaci√≥n √∫til para predecir el sesgo

### 1. Raw Deltas (Diferencias Brutas)

La forma m√°s simple: usar los pasos directamente.

```python
# Ventana de 20 pasos
window = [10, 11, 9, 10, 12, 13, 11, 10, 12, 14, 
          15, 13, 14, 16, 17, 15, 16, 18, 19, 17]

# Calcular deltas (diferencias)
deltas = [11-10, 9-11, 10-9, 12-10, ...]
#       = [1, -2, 1, 2, 1, -2, 1, 2, ...]

# Estas deltas son nuestras features
# Si hay m√°s +1 que -1 ‚Üí sesgo positivo probable
```

**En c√≥digo:**

```python
from enhanced_model import FeatureConfig, make_windows_from_walks_enhanced

# Solo raw deltas
feature_config = FeatureConfig(use_raw_deltas=True)

X, y, groups = make_windows_from_walks_enhanced(
    positions,
    window=20,
    feature_config=feature_config
)

print(f"Features por muestra: {X.shape[1]}")  # 20 (el tama√±o de ventana)
```

**Ventajas:** Simple, directo  
**Desventajas:** Pierde informaci√≥n agregada

### 2. Statistical Features (Caracter√≠sticas Estad√≠sticas)

Agregar informaci√≥n resumida de la ventana.

```python
# Misma ventana
deltas = [1, -2, 1, 2, 1, -2, 1, 2, 1, 2, ...]

# Estad√≠sticas
mean = np.mean(deltas)      # Media: ¬øtiende a subir o bajar?
std = np.std(deltas)        # Volatilidad: ¬øqu√© tan err√°tico?
skew = scipy.stats.skew(deltas)  # Asimetr√≠a: ¬øm√°s +1 o -1?
kurtosis = scipy.stats.kurtosis(deltas)  # Colas pesadas
range_val = max(deltas) - min(deltas)  # Rango de movimiento
```

**Interpretaci√≥n:**

| Estad√≠stica | Valor | Interpretaci√≥n |
|-------------|-------|----------------|
| **Mean > 0** | +0.15 | Tendencia alcista |
| **Mean < 0** | -0.20 | Tendencia bajista |
| **Std alta** | 1.5 | Muy vol√°til |
| **Skew > 0** | +0.8 | M√°s valores positivos |
| **Skew < 0** | -0.8 | M√°s valores negativos |

**En c√≥digo:**

```python
# Raw deltas + estad√≠sticas
feature_config = FeatureConfig(
    use_raw_deltas=True,
    use_statistics=True,
    statistics=["mean", "std", "skew", "range"]
)

X, y, groups = make_windows_from_walks_enhanced(
    positions,
    window=20,
    feature_config=feature_config
)

print(f"Features por muestra: {X.shape[1]}")  
# 20 (deltas) + 4 (estad√≠sticas) = 24
```

**Resultado t√≠pico:** +5-10% mejora en ROC-AUC

### 3. Trend Features (Caracter√≠sticas de Tendencia)

Capturar la direcci√≥n del movimiento.

```python
from scipy.stats import linregress

# Misma ventana
deltas = [1, -2, 1, 2, 1, -2, 1, 2, 1, 2, ...]
time = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...]

# Regresi√≥n lineal
slope, intercept, r_value, _, _ = linregress(time, deltas)

# Features de tendencia
trend_slope = slope         # ¬øSube o baja con el tiempo?
trend_correlation = r_value # ¬øQu√© tan fuerte es la tendencia?
```

**Interpretaci√≥n:**

| Feature | Valor | Significado |
|---------|-------|-------------|
| **slope > 0** | +0.05 | Acelerando hacia arriba |
| **slope < 0** | -0.05 | Desacelerando |
| **r_value alto** | 0.8 | Tendencia clara |
| **r_value bajo** | 0.1 | Sin tendencia clara |

**En c√≥digo:**

```python
# Todas las features
feature_config = FeatureConfig(
    use_raw_deltas=True,
    use_statistics=True,
    use_trend=True,
    statistics=["mean", "std", "skew", "range"]
)

X, y, groups = make_windows_from_walks_enhanced(
    positions,
    window=20,
    feature_config=feature_config
)

print(f"Features totales: {X.shape[1]}")
# 20 (deltas) + 4 (stats) + 2 (trend) = 26
```

**Resultado t√≠pico:** +3-8% mejora adicional

### 4. Sliding Windows (Ventanas Deslizantes)

**Concepto clave:** De un walk largo, extraemos m√∫ltiples muestras.

```
Walk completo (500 pasos):
[10, 11, 9, 10, 12, 13, 11, 10, 12, 14, 15, 13, 14, 16, ...]

Ventana 1 (pasos 0-19):    [10, 11, 9, 10, 12, 13, 11, 10, 12, 14, 15, 13, 14, 16, 17, 15, 16, 18, 19, 17]
Ventana 2 (pasos 1-20):        [11, 9, 10, 12, 13, 11, 10, 12, 14, 15, 13, 14, 16, 17, 15, 16, 18, 19, 17, 20]
Ventana 3 (pasos 2-21):            [9, 10, 12, 13, 11, 10, 12, 14, 15, 13, 14, 16, 17, 15, 16, 18, 19, 17, 20, 18]
...
```

**Ventaja:** De 100 walks de 500 pasos ‚Üí ¬°Miles de muestras de entrenamiento!

**‚ö†Ô∏è PELIGRO:** Ventanas del mismo walk est√°n correlacionadas ‚Üí necesitamos **Group-Aware Validation**

---

## ü§ñ Modelos de Machine Learning

### 1. Dummy Classifiers (Baselines)

**¬øPor qu√© empezar aqu√≠?** Para saber si realmente estamos aprendiendo algo.

#### Dummy Majority

```python
from enhanced_model import build_pipeline

# Siempre predice la clase mayoritaria
model = build_pipeline("dummy_majority")
model.fit(X_train, y_train)
score = model.score(X_test, y_test)

print(f"Accuracy: {score:.3f}")  # ~0.50 si clases balanceadas
```

**Estrategia:** Ignora las features, siempre dice "clase mayoritaria"

**Ejemplo:**
- Si 60% son sesgados positivos, siempre predice "positivo"
- Accuracy: 60% pero no aprendi√≥ nada √∫til

#### Dummy Stratified

```python
model = build_pipeline("dummy_stratified")
# Predice aleatoriamente seg√∫n proporci√≥n de clases
```

**Si tus modelos reales no superan estos baselines ‚Üí No hay se√±al en los datos**

### 2. Logistic Regression (Regresi√≥n Log√≠stica)

**Modelo lineal** m√°s simple para clasificaci√≥n.

#### ¬øC√≥mo funciona?

```python
# Modelo lineal
z = w1*feature1 + w2*feature2 + ... + wn*featuren + b

# Funci√≥n sigmoide para probabilidad
probability = 1 / (1 + exp(-z))

# Decisi√≥n
if probability > 0.5:
    prediction = "sesgado"
else:
    prediction = "justo"
```

**Visualizaci√≥n 2D:**

```
Feature 2
    |     
  1 |    ‚óè‚óè‚óè    Clase 1 (sesgado)
    |   ‚óè‚óè‚óè
  0 |‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  L√≠mite de decisi√≥n (l√≠nea recta)
    | ‚óã‚óã‚óã
 -1 | ‚óã‚óã‚óã‚óã     Clase 0 (justo)
    |________________
       -1   0   1
           Feature 1
```

**Ventajas:**
- ‚úÖ R√°pido de entrenar
- ‚úÖ Interpretable (puedes ver los pesos)
- ‚úÖ Funciona bien con features lineales

**Desventajas:**
- ‚ùå No captura relaciones no lineales
- ‚ùå Asume independencia entre features

**En c√≥digo:**

```python
from enhanced_model import build_pipeline

# Crear pipeline
model = build_pipeline("logreg")

# Entrenar
model.fit(X_train, y_train)

# Evaluar
from enhanced_model import evaluate
metrics = evaluate(model, X_test, y_test)

print(f"ROC-AUC: {metrics['roc_auc']:.3f}")  # ~0.55-0.65
print(f"Accuracy: {metrics['accuracy']:.3f}")  # ~0.58-0.68
```

**¬øCu√°ndo usar?**
- Baseline r√°pido
- Datos linealmente separables
- Necesitas interpretabilidad

### 3. Random Forest (Bosque Aleatorio)

**Ensemble de √°rboles de decisi√≥n** que vota.

#### ¬øC√≥mo funciona?

```
Random Forest = √Årbol 1 + √Årbol 2 + ... + √Årbol 100

Cada √°rbol:
1. Toma muestra aleatoria de datos
2. Toma subconjunto aleatorio de features
3. Construye √°rbol de decisi√≥n
4. Vota en la predicci√≥n final
```

**Visualizaci√≥n de un √°rbol:**

```
                [Todas las muestras]
                        |
                   mean > 0.1?
                   /          \
                 S√≠            No
                 /              \
         [Sesgo positivo]    std > 0.5?
                             /        \
                           S√≠          No
                          /              \
                  [Vol√°til]          [Justo]
```

**Ventajas:**
- ‚úÖ Captura relaciones no lineales
- ‚úÖ Robusto a outliers
- ‚úÖ Feature importance autom√°tico
- ‚úÖ No requiere normalizaci√≥n

**Desventajas:**
- ‚ùå M√°s lento que regresi√≥n log√≠stica
- ‚ùå Menos interpretable
- ‚ùå Puede sobreajustar con muchos √°rboles

**Hiperpar√°metros importantes:**

```python
from enhanced_model import build_pipeline

model = build_pipeline("rf")

# Ver hiperpar√°metros por defecto
print(model.named_steps['clf'].get_params())

# Hiperpar√°metros clave:
# - n_estimators: N√∫mero de √°rboles (default: 100)
# - max_depth: Profundidad m√°xima (default: None)
# - min_samples_split: Min muestras para dividir (default: 2)
# - max_features: Features por √°rbol (default: 'sqrt')
```

**En c√≥digo con tuning:**

```python
from enhanced_model import tune_with_cv

# Grid de hiperpar√°metros
param_grid = {
    'clf__n_estimators': [50, 100, 200],
    'clf__max_depth': [5, 10, None],
    'clf__min_samples_split': [2, 5, 10]
}

# B√∫squeda con CV
best_model = tune_with_cv(
    "rf",
    X_train, y_train, groups_train,
    param_grid=param_grid,
    n_splits=5
)

print(f"Mejores par√°metros: {best_model.best_params_}")
```

**Performance t√≠pico:** ROC-AUC 0.65-0.75

### 4. Histogram Gradient Boosting (HGB)

**El m√°s potente** de los modelos en este proyecto.

#### ¬øC√≥mo funciona?

```
Gradient Boosting = Modelo 1 + Modelo 2 + ... + Modelo N

Iteraci√≥n 1: Entrena modelo inicial ‚Üí errores grandes
Iteraci√≥n 2: Entrena modelo para corregir errores del anterior
Iteraci√≥n 3: Entrena modelo para corregir errores acumulados
...
Iteraci√≥n N: Predicci√≥n final = suma de todos los modelos
```

**Analog√≠a:** Como un equipo donde cada miembro corrige errores del anterior.

**Histogram-based:** Agrupa features en "bins" (histogramas) para ser m√°s r√°pido.

```
Feature continua:     [0.1, 0.15, 0.18, 0.22, 0.25, 0.3, ...]
                              ‚Üì
Bins (256 valores):   [Bin 1, Bin 1, Bin 2, Bin 2, Bin 3, ...]
```

**Ventajas:**
- ‚úÖ **Mejor performance** en la mayor√≠a de casos
- ‚úÖ R√°pido (gracias a histogramas)
- ‚úÖ Maneja missing values
- ‚úÖ Regularizaci√≥n incorporada

**Desventajas:**
- ‚ùå M√°s hiperpar√°metros para tuning
- ‚ùå Puede sobreajustar si no se regulariza
- ‚ùå Menos interpretable que Random Forest

**Hiperpar√°metros clave:**

```python
from enhanced_model import build_pipeline

model = build_pipeline("hgb")

# Hiperpar√°metros importantes:
# - max_iter: N√∫mero de iteraciones (default: 100)
# - max_depth: Profundidad de √°rboles (default: None)
# - learning_rate: Tasa de aprendizaje (default: 0.1)
# - min_samples_leaf: Min muestras en hoja (regularizaci√≥n)
# - l2_regularization: Regularizaci√≥n L2 (default: 0)
```

**Configuraci√≥n recomendada:**

```python
# Para evitar overfitting
model = build_pipeline("hgb")
model.set_params(
    clf__max_depth=6,           # Limitar profundidad
    clf__learning_rate=0.1,      # Learning rate moderado
    clf__min_samples_leaf=20,    # Regularizaci√≥n
    clf__l2_regularization=0.1   # Penalizaci√≥n L2
)

model.fit(X_train, y_train)
```

**Performance t√≠pico:** ROC-AUC 0.70-0.80

### Comparaci√≥n de Modelos

| Modelo | Velocidad | Performance | Interpretabilidad | Cu√°ndo Usar |
|--------|-----------|-------------|-------------------|-------------|
| **Dummy** | ‚ö°‚ö°‚ö° | ‚ùå | ‚úÖ‚úÖ‚úÖ | Baseline |
| **LogReg** | ‚ö°‚ö°‚ö° | üü® | ‚úÖ‚úÖ‚úÖ | R√°pido, lineal |
| **Random Forest** | ‚ö°‚ö° | üü© | ‚úÖ‚úÖ | No lineal, robusto |
| **HGB** | ‚ö°‚ö° | üü©üü© | ‚úÖ | Mejor performance |

**Estrategia recomendada:**

1. **Empieza con Dummy** ‚Üí Baseline
2. **Prueba LogReg** ‚Üí ¬øEs lineal el problema?
3. **Prueba Random Forest** ‚Üí ¬øMejora con no linealidad?
4. **Afina HGB** ‚Üí M√°ximo performance

---

## üìä Validaci√≥n y M√©tricas

### ¬øPor qu√© no solo Accuracy?

**Problema:** Accuracy puede enga√±ar.

```python
# Dataset: 95% clase 0, 5% clase 1
# Modelo dummy que siempre predice 0
# Accuracy: 95% ¬°Pero es in√∫til!
```

### M√©tricas Explicadas

#### 1. Accuracy (Exactitud)

```python
accuracy = (TP + TN) / (TP + TN + FP + FN)
```

- **TP** (True Positive): Predijo sesgado Y era sesgado ‚úÖ
- **TN** (True Negative): Predijo justo Y era justo ‚úÖ
- **FP** (False Positive): Predijo sesgado pero era justo ‚ùå
- **FN** (False Negative): Predijo justo pero era sesgado ‚ùå

**Cu√°ndo usar:** Clases balanceadas (50/50)

#### 2. Precision (Precisi√≥n)

```python
precision = TP / (TP + FP)
```

**Pregunta:** De los que predije como "sesgados", ¬øcu√°ntos realmente lo eran?

**Ejemplo:**
- Predije 100 como sesgados
- 80 realmente lo eran
- Precision = 80/100 = 0.80

**Cu√°ndo importa:** Cuando los falsos positivos son costosos (ej. alertas de fraude)

#### 3. Recall (Sensibilidad)

```python
recall = TP / (TP + FN)
```

**Pregunta:** De todos los realmente "sesgados", ¬øcu√°ntos detect√©?

**Ejemplo:**
- Hab√≠a 90 sesgados reales
- Detect√© 80 de ellos
- Recall = 80/90 = 0.89

**Cu√°ndo importa:** Cuando los falsos negativos son costosos (ej. detecci√≥n de enfermedades)

#### 4. F1-Score

```python
f1 = 2 * (precision * recall) / (precision + recall)
```

**Qu√© mide:** Balance entre precision y recall

**Cu√°ndo usar:** Cuando quieres un balance y las clases est√°n desbalanceadas

#### 5. ROC-AUC (√Årea Bajo la Curva ROC)

**La m√©trica m√°s importante en este proyecto.**

**ROC Curve:** Gr√°fica de True Positive Rate vs False Positive Rate

```
True Positive Rate (TPR)
    |
1.0 |    ___/‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ    ‚Üê Modelo perfecto
    |   /
0.8 |  /  ‚Üê Nuestro modelo
    | /
0.5 |/____________    ‚Üê Modelo aleatorio (diagonal)
    |
0.0 |________________
   0.0  0.5  0.8  1.0
   False Positive Rate (FPR)
```

**AUC (Area Under Curve):**

| AUC | Interpretaci√≥n |
|-----|----------------|
| **0.50** | Aleatorio (moneda al aire) |
| **0.50-0.60** | Se√±al muy d√©bil |
| **0.60-0.70** | Se√±al aceptable |
| **0.70-0.80** | Buena se√±al |
| **0.80-0.90** | Excelente se√±al |
| **0.90-1.00** | Casi perfecto (cuidado con overfitting) |

**Por qu√© usamos ROC-AUC:**
- ‚úÖ Insensible a clases desbalanceadas
- ‚úÖ Mide capacidad de discriminaci√≥n
- ‚úÖ Independiente del threshold
- ‚úÖ F√°cil de interpretar

**En c√≥digo:**

```python
from enhanced_model import evaluate

metrics = evaluate(model, X_test, y_test)

print(f"Accuracy: {metrics['accuracy']:.3f}")
print(f"Precision: {metrics['precision']:.3f}")
print(f"Recall: {metrics['recall']:.3f}")
print(f"F1-Score: {metrics['f1']:.3f}")
print(f"ROC-AUC: {metrics['roc_auc']:.3f}")  # ‚Üê M√©trica principal
```

#### 6. Matthews Correlation Coefficient (MCC)

```python
MCC = (TP*TN - FP*FN) / sqrt((TP+FP)(TP+FN)(TN+FP)(TN+FN))
```

**Rango:** -1 (peor) a +1 (perfecto), 0 = aleatorio

**Ventaja:** Funciona bien con clases desbalanceadas

#### 7. Cohen's Kappa

**Mide:** Acuerdo entre predicciones y realidad, ajustado por azar

**Interpretaci√≥n:**
- Œ∫ < 0: Peor que azar
- Œ∫ = 0-0.20: Leve
- Œ∫ = 0.21-0.40: Aceptable
- Œ∫ = 0.41-0.60: Moderado
- Œ∫ = 0.61-0.80: Sustancial
- Œ∫ = 0.81-1.00: Casi perfecto

---

## üîí Group-Aware Validation (El Concepto Cr√≠tico)

### El Problema del Data Leakage

**Escenario:** Tienes 100 walks, cada uno genera 480 ventanas (sliding windows).

```
Walk 1: [Ventana 1, Ventana 2, Ventana 3, ..., Ventana 480]
Walk 2: [Ventana 1, Ventana 2, Ventana 3, ..., Ventana 480]
...
Walk 100: [...]

Total: 100 √ó 480 = 48,000 muestras
```

**‚ùå MAL - Train/Test Split Normal:**

```python
# ESTO EST√Å MAL
X_train, X_test = train_test_split(X, y, test_size=0.2)

# Problema: Ventanas del mismo walk est√°n en train Y test
# Walk 1 ‚Üí Ventanas 1-380 en train, 381-480 en test
# Las ventanas est√°n correlacionadas ‚Üí LEAKAGE!
```

**Resultado:** Performance inflada artificialmente (overfitting)

**Por qu√© es malo:**

```
Train: Walk1[ventana 100], Walk1[ventana 101], Walk1[ventana 102], ...
Test:  Walk1[ventana 103], Walk1[ventana 104], ...

¬°Ventana 103 es casi id√©ntica a ventana 102!
El modelo "memoriza" el walk, no aprende patrones generales
```

### La Soluci√≥n: Group-Aware Validation

**‚úÖ BIEN - Split por Walk Completo:**

```python
# ESTO EST√Å BIEN
from enhanced_model import group_train_test_split

X_train, X_test, y_train, y_test, g_train, g_test = group_train_test_split(
    X, y, groups,  # ‚Üê groups identifica qu√© ventanas vienen del mismo walk
    test_size=0.2,
    seed=42
)

# Resultado: Si Walk 1 est√° en test, TODAS sus ventanas est√°n en test
# Train: Walk 1-80 (TODAS sus ventanas)
# Test:  Walk 81-100 (TODAS sus ventanas)
```

**Visualizaci√≥n:**

```
‚ùå MAL:
Train: [W1-vent1, W1-vent2, W2-vent1, W3-vent1, W1-vent3, ...]
Test:  [W1-vent4, W2-vent2, W3-vent2, ...]
       ‚Üë LEAKAGE! W1 en ambos sets

‚úÖ BIEN:
Train: [W1-todas, W2-todas, W3-todas, ..., W80-todas]
Test:  [W81-todas, W82-todas, ..., W100-todas]
       ‚Üë Sin leakage, walks completamente separados
```

### Group K-Fold Cross-Validation

**CV normal (MAL):**

```python
# Fold 1: Train en 80%, test en 20% (walks mezclados)
# Fold 2: Train en 80%, test en 20% (walks mezclados)
# ...
```

**Group K-Fold (BIEN):**

```python
from enhanced_model import tune_with_cv

best_model = tune_with_cv(
    "hgb",
    X_train, y_train, groups_train,  # ‚Üê groups parameter
    n_splits=5
)

# Fold 1: Train walks 1-80,   Test walks 81-100
# Fold 2: Train walks 1-60,81-100, Test walks 61-80
# ...
# Cada walk SIEMPRE completo en un solo fold
```

### Implementaci√≥n en C√≥digo

```python
# 1. Generar walks
positions, p_ups = generate_random_walks_1d(config)

# 2. Extraer ventanas (MANTENER groups)
X, y, groups = make_windows_from_walks_enhanced(
    positions,
    window=20
)

print(f"Muestras: {X.shape[0]}")  # 48,000
print(f"Walks √∫nicos: {len(np.unique(groups))}")  # 100

# 3. Split group-aware
X_train, X_test, y_train, y_test, g_train, g_test = group_train_test_split(
    X, y, groups, test_size=0.2
)

# Verificar separaci√≥n
train_walks = set(g_train)
test_walks = set(g_test)
print(f"Intersecci√≥n: {train_walks & test_walks}")  # set() - ¬°Vac√≠o!

# 4. Entrenar normalmente
model = build_pipeline("hgb")
model.fit(X_train, y_train)

# 5. Evaluar (performance realista)
metrics = evaluate(model, X_test, y_test)
print(f"ROC-AUC: {metrics['roc_auc']:.3f}")  # Performance real, sin leakage
```

### Impacto en Performance

**Ejemplo real:**

| M√©todo | ROC-AUC Train | ROC-AUC Test | Interpretaci√≥n |
|--------|---------------|--------------|----------------|
| ‚ùå **Sin Group-Aware** | 0.95 | 0.92 | ¬°Sospechoso! Muy alto |
| ‚úÖ **Con Group-Aware** | 0.78 | 0.72 | Realista, generaliza |

**Diferencia de 0.92 ‚Üí 0.72 = 0.20 (20% del performance era overfitting!)**

### Cu√°ndo Aplicar Group-Aware

**Siempre que tengas:**
- Time series con ventanas deslizantes
- M√∫ltiples muestras del mismo sujeto/entidad
- Datos correlacionados de la misma fuente
- Mediciones repetidas

**Ejemplos:**
- ‚úÖ Random walks (este proyecto)
- ‚úÖ Series temporales financieras
- ‚úÖ Sensores IoT
- ‚úÖ Pacientes en estudios m√©dicos
- ‚úÖ Usuarios en sistemas de recomendaci√≥n

---

## üéì Ejercicios Pr√°cticos

### Ejercicio 1: Detectar Fair vs Biased (B√°sico)

**Objetivo:** Entrenar tu primer modelo para detectar sesgo.

```python
# 1. Imports
from enhanced_model import (
    WalkConfig, generate_random_walks_1d,
    make_windows_from_walks_enhanced,
    group_train_test_split, build_pipeline, evaluate
)

# 2. Generar datos
config = WalkConfig(
    n_walks=50,
    n_steps=300,
    bias_mode="mixed"
)
positions, p_ups = generate_random_walks_1d(config)

# 3. Features (solo raw deltas)
X, y, groups = make_windows_from_walks_enhanced(positions, window=20)

# 4. Split
X_train, X_test, y_train, y_test, g_train, g_test = group_train_test_split(
    X, y, groups, test_size=0.2
)

# 5. Entrenar
model = build_pipeline("logreg")
model.fit(X_train, y_train)

# 6. Evaluar
metrics = evaluate(model, X_test, y_test)
print(f"ROC-AUC: {metrics['roc_auc']:.3f}")

# ¬øPregunta?: ¬øSupera 0.50 (baseline)?
```

**Meta:** ROC-AUC > 0.55

### Ejercicio 2: Comparar Feature Engineering

**Objetivo:** Ver el impacto de diferentes features.

```python
from enhanced_model import FeatureConfig

configs = {
    "Solo deltas": FeatureConfig(use_raw_deltas=True),
    "Deltas + Stats": FeatureConfig(
        use_raw_deltas=True,
        use_statistics=True
    ),
    "Todas las features": FeatureConfig(
        use_raw_deltas=True,
        use_statistics=True,
        use_trend=True
    )
}

results = {}
for name, feat_config in configs.items():
    X, y, groups = make_windows_from_walks_enhanced(
        positions,
        window=20,
        feature_config=feat_config
    )
    
    X_train, X_test, y_train, y_test, _, _ = group_train_test_split(
        X, y, groups, test_size=0.2
    )
    
    model = build_pipeline("rf")
    model.fit(X_train, y_train)
    
    metrics = evaluate(model, X_test, y_test)
    results[name] = metrics['roc_auc']
    print(f"{name}: {metrics['roc_auc']:.3f}")

# ¬øPregunta?: ¬øQu√© configuraci√≥n es mejor?
```

### Ejercicio 3: Comparar Modelos

**Objetivo:** Encontrar el mejor modelo para tu problema.

```python
models = ["logreg", "rf", "hgb"]

for model_name in models:
    model = build_pipeline(model_name)
    model.fit(X_train, y_train)
    
    metrics = evaluate(model, X_test, y_test)
    print(f"\n{model_name.upper()}:")
    print(f"  ROC-AUC: {metrics['roc_auc']:.3f}")
    print(f"  Accuracy: {metrics['accuracy']:.3f}")
    print(f"  F1-Score: {metrics['f1']:.3f}")

# ¬øPregunta?: ¬øQu√© modelo es mejor? ¬øVale la pena la complejidad?
```

### Ejercicio 4: Demostrar Data Leakage

**Objetivo:** Ver por ti mismo el problema del leakage.

```python
from sklearn.model_selection import train_test_split

# MAL: Split normal (con leakage)
X_train_bad, X_test_bad, y_train_bad, y_test_bad = train_test_split(
    X, y, test_size=0.2, random_state=42
)

model_bad = build_pipeline("hgb")
model_bad.fit(X_train_bad, y_train_bad)
metrics_bad = evaluate(model_bad, X_test_bad, y_test_bad)

# BIEN: Split group-aware
X_train_good, X_test_good, y_train_good, y_test_good, _, _ = group_train_test_split(
    X, y, groups, test_size=0.2, seed=42
)

model_good = build_pipeline("hgb")
model_good.fit(X_train_good, y_train_good)
metrics_good = evaluate(model_good, X_test_good, y_test_good)

# Comparar
print(f"‚ùå Sin Group-Aware: ROC-AUC = {metrics_bad['roc_auc']:.3f}")
print(f"‚úÖ Con Group-Aware: ROC-AUC = {metrics_good['roc_auc']:.3f}")
print(f"Diferencia: {(metrics_bad['roc_auc'] - metrics_good['roc_auc']):.3f}")

# ¬øPregunta?: ¬øCu√°nto overfitting hay sin group-aware?
```

### Ejercicio 5: An√°lisis de Feature Importance

**Objetivo:** Entender qu√© features son m√°s importantes.

```python
from enhanced_model import get_feature_importance

# Entrenar Random Forest
model = build_pipeline("rf")
model.fit(X_train, y_train)

# Extraer importancia
feature_names = [f"delta_{i}" for i in range(20)] + ["mean", "std", "skew"]
importances = get_feature_importance(model, feature_names)

# Visualizar top 10
import matplotlib.pyplot as plt

top_10 = importances.head(10)
plt.barh(top_10['feature'], top_10['importance'])
plt.xlabel('Importance')
plt.title('Top 10 Features')
plt.tight_layout()
plt.show()

# ¬øPregunta?: ¬øSon las estad√≠sticas m√°s importantes que los deltas?
```

### Ejercicio 6: Experimento Completo

**Objetivo:** Dise√±ar y ejecutar un experimento completo.

**Hip√≥tesis:** "Aumentar el window size mejora la performance"

```python
window_sizes = [10, 20, 30, 50, 100]
results = []

for window in window_sizes:
    X, y, groups = make_windows_from_walks_enhanced(
        positions,
        window=window
    )
    
    X_train, X_test, y_train, y_test, _, _ = group_train_test_split(
        X, y, groups, test_size=0.2
    )
    
    model = build_pipeline("hgb")
    model.fit(X_train, y_train)
    
    metrics = evaluate(model, X_test, y_test)
    results.append({
        'window': window,
        'roc_auc': metrics['roc_auc'],
        'n_samples': len(X)
    })
    print(f"Window {window}: ROC-AUC = {metrics['roc_auc']:.3f}, "
          f"Muestras = {len(X)}")

# Visualizar
import pandas as pd
df = pd.DataFrame(results)
df.plot(x='window', y='roc_auc', marker='o')
plt.xlabel('Window Size')
plt.ylabel('ROC-AUC')
plt.title('Performance vs Window Size')
plt.grid(True)
plt.show()

# ¬øConclusi√≥n?: ¬øCu√°l es el window size √≥ptimo?
```

---

## üìö Recursos Adicionales

### Libros Recomendados

1. **"Introduction to Statistical Learning"** (James et al.)
   - Cap√≠tulo 4: Clasificaci√≥n
   - Cap√≠tulo 8: Tree-Based Methods
   - **Gratis online:** https://www.statlearning.com/

2. **"Pattern Recognition and Machine Learning"** (Bishop)
   - Cap√≠tulo 4: Linear Models for Classification

3. **"Hands-On Machine Learning"** (G√©ron)
   - Excelente para scikit-learn

### Cursos Online

1. **Andrew Ng - Machine Learning (Coursera)**
   - Fundamentos s√≥lidos
   - Gratis para auditar

2. **Fast.ai - Practical Deep Learning**
   - Enfoque pr√°ctico

3. **Kaggle Learn**
   - Tutoriales interactivos gratis

### Papers Cient√≠ficos

1. **Random Walks:**
   - Pearson (1905): "The Problem of the Random Walk"
   - Feller (1968): "An Introduction to Probability Theory"

2. **Financial Applications:**
   - Lo & MacKinlay (1999): "A Non-Random Walk Down Wall Street"
   - Malkiel (2015): "A Random Walk Down Wall Street"

3. **Machine Learning:**
   - Breiman (2001): "Random Forests"
   - Friedman (2001): "Greedy Function Approximation: A Gradient Boosting Machine"

### Documentaci√≥n Oficial

1. **scikit-learn:**
   - User Guide: https://scikit-learn.org/stable/user_guide.html
   - API Reference: https://scikit-learn.org/stable/modules/classes.html

2. **NumPy/SciPy:**
   - NumPy: https://numpy.org/doc/
   - SciPy: https://docs.scipy.org/

3. **Matplotlib:**
   - Tutorials: https://matplotlib.org/stable/tutorials/index.html

### Comunidades

1. **Stack Overflow**
   - Tag: `scikit-learn`, `machine-learning`

2. **Reddit**
   - r/MachineLearning
   - r/learnmachinelearning
   - r/datascience

3. **Kaggle**
   - Competitions para practicar
   - Notebooks p√∫blicos para aprender

### Proyectos Relacionados

1. **Scikit-learn Examples**
   - https://scikit-learn.org/stable/auto_examples/

2. **Kaggle Kernels**
   - Buscar "random walk", "time series classification"

3. **GitHub Topics**
   - #time-series-classification
   - #feature-engineering
   - #gradient-boosting

---

## üéØ Checklist de Aprendizaje

Marca lo que ya dominas:

### Conceptos B√°sicos
- [ ] Entiendo qu√© es un random walk
- [ ] Distingo entre walk justo y sesgado
- [ ] S√© qu√© es una ventana deslizante
- [ ] Entiendo el concepto de features

### Feature Engineering
- [ ] Puedo explicar raw deltas
- [ ] Entiendo estad√≠sticas (mean, std, skew)
- [ ] Comprendo trend features (slope, correlation)
- [ ] S√© cu√°ndo usar cada tipo de feature

### Modelos
- [ ] Entiendo regresi√≥n log√≠stica
- [ ] S√© c√≥mo funciona Random Forest
- [ ] Comprendo Gradient Boosting
- [ ] Puedo elegir el modelo adecuado

### Validaci√≥n
- [ ] Distingo entre accuracy, precision y recall
- [ ] Entiendo ROC-AUC
- [ ] S√© por qu√© usamos baselines
- [ ] Comprendo el concepto de overfitting

### Group-Aware Validation
- [ ] Entiendo el problema del data leakage
- [ ] S√© implementar group-aware split
- [ ] Uso GroupKFold para CV
- [ ] Puedo explicar por qu√© es cr√≠tico

### Pr√°ctico
- [ ] Puedo entrenar un modelo b√°sico
- [ ] S√© interpretar las m√©tricas
- [ ] Puedo comparar modelos
- [ ] Entiendo feature importance
- [ ] S√© dise√±ar experimentos

---

## üöÄ Pr√≥ximos Pasos

1. **Practica con los ejercicios** de esta gu√≠a
2. **Lee el c√≥digo** en `enhanced_model.py` l√≠nea por l√≠nea
3. **Ejecuta el notebook** `random_walk_prediction_fast-Copy1.ipynb`
4. **Experimenta** con tus propios par√°metros
5. **Lee los ejemplos** en `examples/` para aplicaciones reales
6. **Contribuye** al proyecto con mejoras

---

## ‚ùì Preguntas Frecuentes

### ¬øPor qu√© Random Walks?

Los random walks son un modelo simple que aparece en muchos fen√≥menos reales: precios de acciones, movimiento browniano, procesos de difusi√≥n, etc. Si puedes detectar patrones aqu√≠, puedes aplicarlo a problemas reales.

### ¬øEs esto "Deep Learning"?

No, este proyecto usa **Machine Learning tradicional** (scikit-learn). Es m√°s simple, interpretable y suficiente para muchos problemas. Deep Learning (LSTM, transformers) se puede a√±adir despu√©s si es necesario.

### ¬øQu√© ROC-AUC es "bueno"?

Depende del contexto:
- **0.50-0.60:** Se√±al muy d√©bil, quiz√°s no vale la pena
- **0.60-0.70:** Aceptable para exploraci√≥n
- **0.70-0.80:** Bueno, √∫til en producci√≥n
- **0.80+:** Excelente, pero verifica que no hay overfitting

### ¬øC√≥mo evito overfitting?

1. ‚úÖ Usa **group-aware validation** (siempre)
2. ‚úÖ Regularizaci√≥n (L2, max_depth, min_samples_leaf)
3. ‚úÖ Cross-validation con m√∫ltiples folds
4. ‚úÖ Compara train vs test performance
5. ‚úÖ Usa baselines para verificar

### ¬øPuedo usar esto para trading real?

**Con precauci√≥n.** Este proyecto es educativo. Para trading real:
- Necesitas muchos m√°s features (fundamentales, sentimiento, etc.)
- Considera costos de transacci√≥n
- Implementa risk management
- Backtesting riguroso
- Empieza con paper trading

### ¬øQu√© m√°s puedo aprender?

- **Deep Learning:** LSTM, GRU para series temporales
- **Online Learning:** Actualizar modelos en tiempo real
- **Ensemble Methods:** Combinar m√∫ltiples modelos
- **Feature Selection:** Elegir features autom√°ticamente
- **Hyperparameter Optimization:** Optuna, Hyperopt

---

**¬øTienes m√°s preguntas?** Abre un issue en GitHub o contribuye a esta gu√≠a. ¬°El aprendizaje es colaborativo! üéì

---

<div align="center">

**¬°Feliz aprendizaje! üöÄ**

[‚¨ÖÔ∏è Volver al README](README.md) ‚Ä¢ [üìä Ver Ejemplos](examples/) ‚Ä¢ [üß™ Ejecutar Tests](tests/)

</div>
